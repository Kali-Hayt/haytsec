## 7.4.5 Load Balancers
#load-balancers #networking-plus 
Load balancers are used to distribute client requests across multiple servers (nodes) that perform the same function—such as web, email, or media streaming servers. This distribution improves performance, reliability, and fault tolerance.

🧱 **Definition**  
A **load balancer** can be a hardware appliance or software application. It acts as a front-end between clients and server farms, managing traffic and redirecting requests based on specific logic.

🧱 **Use Cases**
- Web servers
- Front-end email servers
- Video conferencing or streaming platforms
- DDoS mitigation (helps distribute and deflect flood traffic)

🧱 **How It Works**
- Load balancers are placed in front of the server network.
- Clients connect to a **virtual IP address** that represents the service.
- The load balancer routes that connection to one of the real backend servers.
- This enables **scalability**, **availability**, and **resilience**.

---

### 🔀 Types of Load Balancers

#### ✅ Layer 4 Switch (Transport Layer)
- Works at **OSI Layer 4**
- Makes decisions using **IP address + TCP/UDP ports**
- Fast and simple
- Example: round-robin TCP distribution across web servers

#### ✅ Layer 7 Switch (Content Switch)
- Works at **OSI Layer 7 (Application Layer)**
- Makes decisions based on **application data**, like:
  - Specific URLs
  - File types (e.g., video vs. image)
  - Cookies, headers, etc.
- More advanced logic but needs more processing power

🔍 *Note*: These are sometimes called **multilayer switches**, even though we typically associate switching with Layer 2 (Ethernet).

---

### 🧱 Benefits of Load Balancers
- **Distributes load** to prevent server overload
- **Increases uptime** with failover to healthy servers
- **Improves scalability** for web and cloud applications
- **Supports redundancy** and high availability
- **Can defend against DDoS attacks** by absorbing or spreading out malicious traffic

---

