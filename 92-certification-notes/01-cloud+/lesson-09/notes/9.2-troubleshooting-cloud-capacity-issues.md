## 9.2 Troubleshooting Cloud Capacity Issues  


---

### ğŸ§± What Is Capacity?

**Capacity** is the max workload a system (hardware or software) can handle.

- For cloud resources, it's the maximum number of users, VMs, or requests that can be supported.
- Exceeding capacity leads to:
  - ğŸ¢ Sluggish performance
  - âŒ Service unavailability
  - ğŸ“‰ System instability

---

### âœ… Why It Matters

- All systems have a limit â€” even â€œscalableâ€ cloud services.
- Cloud vendors may throttle or deny resource requests when:
  - Your usage hits a hard cap.
  - The region or zone you're in has run out of resources (rare, but real).
  - Misconfigured autoscaling fails to trigger.

---

### ğŸ› ï¸ Troubleshooting Capacity Issues

- **Start with metrics**: Check CPU, memory, disk I/O, network throughput.
- **Check autoscaling**: Did it trigger? Is it misconfigured?
- **Inspect limits**:
  - AWS EC2 instance limits (per region/account)
  - Azure VM quotas
  - GCP per-service quotas

---

### ğŸ“Š How to Measure Capacity

- Calculate **user density**: How many users per VM/container before latency spikes?
- Observe **baseline performance**: Compare off-peak to peak metrics.
- Use **monitoring tools**:
  - CloudWatch (AWS)
  - Azure Monitor
  - GCP Operations Suite

---

### ğŸ§  Pro Tip: Think Like a Firefighter

Cloud capacity failures aren't "if", they're "when."  
Donâ€™t wait for smoke. Design alerts and dashboards that flag:

- High CPU/mem
- Scaling delays
- Rejected API/resource allocation calls

---

### âœ… Key Takeaway

**Capacity planning** prevents problems.  
**Capacity troubleshooting** fixes what poor planning missed.

---
### ğŸ§± API Request Capacity

APIs are cloud resources with usage limits â€” they're not infinite, and theyâ€™re often throttled or billed.

- API requests are metered based on volume over time  
- Capacity is usually measured in requests per second (RPS)  
- Example: a cloud database may allow 100 write requests/sec  
- Exceeding that:
  - âŒ Triggers throttling
  - ğŸ’¸ May incur extra charges
  - ğŸ¢ Slows down the app or causes errors

---

### âœ… Why It Matters

- APIs are often the glue of cloud systems  
- If your requests exceed limits:
  - You may lose availability
  - Users see failed actions or delayed results
- Baseline tracking helps compare real usage vs. allowed capacity  

---

### ğŸ› ï¸ Troubleshooting API Capacity

- Start with your logs: check for throttling, rate limit errors, or slow response times  
- Review monitoring tools:
  - ğŸ“Š Compare actual usage to allowed RPS  
  - Watch for usage spikes or abnormal patterns  
- You may need to:
  - Request higher limits (contracted API capacity)
  - Split traffic across multiple endpoints

---

### ğŸ” Analogy: Like a Ticket Booth

- An API is like a ticket window at a concert  
- It can serve only so many people per second  
- Too many people = line backs up, people get turned away  
- Your baseline = normal crowd size  
- Your API cap = how fast the window can serve  
---
### ğŸ§± Bandwidth

Bandwidth is how much data your network can handle at a time â€” like the width of a highway.

- If bandwidth is too low:
  - ğŸ¢ Network latency increases
  - âŒ App timeouts and degraded performance
  - ğŸ˜  Customer frustration (especially in e-commerce)

---

### âœ… What Affects Bandwidth

- Network adapters have different speeds (e.g., 1 Gbps to 100+ Gbps)  
- These speeds should be part of your baseline network metrics  
- For high-speed or low-latency apps:
  - Place VMs in the same placement group  
  - Use high-speed NICs to reduce cross-traffic lag

---

### ğŸŒ Cloud vs. Private Bandwidth

- In public cloud, bandwidth between the cloud and internet is managed by the provider  
- This link can become a bottleneck if not monitored  
- In private cloud setups:
  - You control bandwidth usage and capacity  
  - ğŸ“ You may need to contact your ISP to upgrade circuits or increase speed  

---

### ğŸ“¦ Analogy: Like a Freight Tunnel

- Bandwidth = width of the tunnel  
- Data = trucks going through it  
- Too narrow = traffic backs up, delivery delays  
- High-speed adapter = multiple lanes  
- Placement group = trucks starting from same warehouse  

---
### ğŸ§± Cloud Batch Job Scheduling

Batch jobs are large, scheduled processing tasks â€” often resource-heavy and time-bound.

- Running batch jobs in the cloud can strain your fleet's compute capacity  
- Underestimating job size leads to:
  - ğŸ¢ Slower execution than expected  
  - ğŸ’¸ Unplanned capacity purchases  
  - âŒ Job failures if autoscaling doesnâ€™t trigger fast enough  

---

### âœ… Autoscaling Can Help

- Autoscaling adds compute power automatically when job demands spike  
- Helps absorb surprise workloads without manual intervention  
- Important for workloads with unpredictable or seasonal spikes  

---

### ğŸ§© Database Impact

- Many batch jobs depend on relational databases  
- Running them can stress the DB â€” especially during:
  - ğŸ” Heavy write operations
  - ğŸ§  Complex queries across large datasets  
- This creates a domino effect of performance issues  

---

### ğŸ› ï¸ Best Practices

- Ensure your DB server can handle job demand  
- If jobs are read-heavy:
  - Deploy enough read replicas to spread the load  
  - Avoid overloading primary DB with read traffic  
- Monitor database metrics during job execution  

---

### ğŸ—ï¸ Analogy: Like a Factory Shift

- Think of a batch job as a night shift at a factory  
- If you donâ€™t staff enough workers (compute), production is delayed  
- If too many workers hit the same machine (DB), it overheats  
- Smart scheduling = balancing tasks, machines, and timing  

---
### ğŸ§± Compute Resources

When creating a VM in the cloud, you define its processing power â€” usually by setting CPU speed and core count.

- Before migration, measure the processing demand of your current system  
- For new deployments:
  - ğŸ“„ Use vendor documentation  
  - ğŸ” Review case studies or benchmarks from similar workloads  

---

### âœ… Monitoring CPU Utilization

- Operating systems provide tools to monitor CPU use  
- CPU load should be tracked as part of your baseline  
- Monitoring trends over time helps you:
  - ğŸ§  Detect performance degradation early  
  - ğŸ”§ Apply fixes before full resource exhaustion  

---

### âš ï¸ What to Do When CPU Starvation Hits

- If CPUs are maxed out, you have two main options:

  - **Scale horizontally**  
    - ğŸ§± Add more servers (VMs)  
    - ğŸ”„ Spread load across multiple instances  
    - â±ï¸ Minimal downtime if designed for it

  - **Scale vertically**  
    - ğŸš€ Upgrade to a higher-tier VM  
    - â¸ï¸ May require downtime during resize  
    - ğŸ§¨ More expensive but stronger individual performance  

---

### ğŸ§  Analogy: Like a Restaurant Kitchen

- VM = chef  
- CPU = how fast they can cook  
- Too many orders = food delays (performance hits)  
- Horizontal scaling = hire more chefs  
- Vertical scaling = replace your chef with Gordon Ramsay  

---
### ğŸ§± Network Addressing

IP planning is a capacity issue â€” once you run out of addresses, your whole deployment can bottleneck.

- Subnet size is defined by the CIDR block  
- CIDR = IP range + subnet mask (e.g., `192.168.0.0/16`)  
- The **smaller** the subnet mask â the **more** IPs available  
  - `10.0.0.0/24` = fewer IPs  
  - `10.0.0.0/8` = many more IPs âœ…  
- Always choose a block that allows for future growth, not just current use

---

### âš ï¸ You Canâ€™t Always Change Later

- Most cloud providers require you to pick a CIDR block **before** deploying  
- Changing it later may force:
  - ğŸ”„ Redeploying all resources  
  - ğŸ”§ Reconfiguring every IP-dependent device  
- This is disruptive and often not worth it  

---

### ğŸ” Reserved IPs

- Some IPs in every CIDR block are **reserved** by the provider  
- Reserved addresses may include:
  - Default gateway (`10.0.0.1` in `10.0.0.0/8`)  
  - DNS and NTP servers  
- These are usually at the **start** of the block  
- ğŸ“„ The cloud provider will document which addresses are off-limits

---

### ğŸ“¦ Analogy: Like a Parking Lot Lease

- CIDR block = size of the parking lot  
- Each IP = parking space  
- Some spaces are always blocked off (reserved)  
- If you run out, youâ€™ll have to tear up the lot and build a new one  

---
### ğŸ§± Storage Capacity

Storage is one of the fastest-growing cloud resources â€” usage tends to rise silently until it breaks things.

- Storage volumes have defined size limits  
- Volume utilization should be tracked constantly  
- Set alerts to notify operations when usage passes a threshold (e.g., 80%)  
- If storage fills up:
  - âŒ Applications can crash  
  - ğŸ§¨ Data loss may occur  
  - â›” Writes may be denied

---

### âœ… How to Handle Storage Capacity

- Use cloud monitoring tools to track volume usage  
- Set automatic alarms and trigger actions at defined thresholds  
- Manage capacity before it reaches 100%  

---

### ğŸ› ï¸ Resolution Options

- ğŸª„ If the storage is elastic (like EBS), increase its size  
- ğŸ”„ Migrate data to a larger volume  
- ğŸ“¦ Archive or clean up unnecessary data  
- ğŸ’¡ Consider lifecycle policies for object storage (e.g., S3 tiering)

---

### ğŸ“¦ Analogy: Like a Bookshelf

- Storage volume = bookshelf  
- Files = books  
- When itâ€™s full:
  - You canâ€™t add more  
  - Some books fall off = data loss  
- Solutions:
  - Get a bigger shelf  
  - Add a second shelf  
  - Remove books you no longer read  

---
### ğŸ§± Variance in Number of Users

User count directly impacts system load â€” and user spikes can overwhelm cloud services if not planned for.

- Track user metrics as part of your performance baseline  
- Two common patterns to measure:
  - ğŸ§­ Total visitors (web traffic over time)  
  - ğŸ” Concurrent logged-in users (session-based apps)  
- Variance tracking helps identify:
  - ğŸ•’ Peak hours
  - ğŸ’¤ Low activity periods
  - ğŸ“ˆ Growth trends

---

### âœ… Why It Matters

- High concurrent user count = high system load  
- Systems must scale to absorb spikes or throttle gracefully  
- Failure to prepare leads to:
  - âŒ Login errors  
  - ğŸ¢ Slow response times  
  - ğŸ’¥ Resource exhaustion  

---

### ğŸ› ï¸ Troubleshooting with User Metrics

- Monitor usage to locate congestion points  
- Map high user periods to infrastructure stress  
- Useful for:
  - Cloud autoscaling triggers  
  - Identifying overused services  
  - Investigating performance slowdowns  

---

### ğŸ” Licensing & Limits

- Some identity and access management systems have max user limits  
- Software license models may be based on:
  - Total users  
  - Concurrent sessions  
  - Usage tiers  
- Track user variance to avoid hitting hard limits  

---

### ğŸ“¦ Analogy: Like a Coffee Shop Rush

- Users = customers walking into the cafÃ©  
- Each logged-in user = one seated at a table  
- More users than chairs = standing room only  
- You either:
  - Buy more tables (scale infra)  
  - Limit access (throttle or queue)  

---
#cloud-plus  
#compute  
#storage  
#networking  
#api  
#baselines  
#monitoring  
