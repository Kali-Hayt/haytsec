## 9.2 Troubleshooting Cloud Capacity Issues  


---

### 🧱 What Is Capacity?

**Capacity** is the max workload a system (hardware or software) can handle.

- For cloud resources, it's the maximum number of users, VMs, or requests that can be supported.
- Exceeding capacity leads to:
  - 🐢 Sluggish performance
  - ❌ Service unavailability
  - 📉 System instability

---

### ✅ Why It Matters

- All systems have a limit — even “scalable” cloud services.
- Cloud vendors may throttle or deny resource requests when:
  - Your usage hits a hard cap.
  - The region or zone you're in has run out of resources (rare, but real).
  - Misconfigured autoscaling fails to trigger.

---

### 🛠️ Troubleshooting Capacity Issues

- **Start with metrics**: Check CPU, memory, disk I/O, network throughput.
- **Check autoscaling**: Did it trigger? Is it misconfigured?
- **Inspect limits**:
  - AWS EC2 instance limits (per region/account)
  - Azure VM quotas
  - GCP per-service quotas

---

### 📊 How to Measure Capacity

- Calculate **user density**: How many users per VM/container before latency spikes?
- Observe **baseline performance**: Compare off-peak to peak metrics.
- Use **monitoring tools**:
  - CloudWatch (AWS)
  - Azure Monitor
  - GCP Operations Suite

---

### 🧠 Pro Tip: Think Like a Firefighter

Cloud capacity failures aren't "if", they're "when."  
Don’t wait for smoke. Design alerts and dashboards that flag:

- High CPU/mem
- Scaling delays
- Rejected API/resource allocation calls

---

### ✅ Key Takeaway

**Capacity planning** prevents problems.  
**Capacity troubleshooting** fixes what poor planning missed.

---
### 🧱 API Request Capacity

APIs are cloud resources with usage limits — they're not infinite, and they’re often throttled or billed.

- API requests are metered based on volume over time  
- Capacity is usually measured in requests per second (RPS)  
- Example: a cloud database may allow 100 write requests/sec  
- Exceeding that:
  - ❌ Triggers throttling
  - 💸 May incur extra charges
  - 🐢 Slows down the app or causes errors

---

### ✅ Why It Matters

- APIs are often the glue of cloud systems  
- If your requests exceed limits:
  - You may lose availability
  - Users see failed actions or delayed results
- Baseline tracking helps compare real usage vs. allowed capacity  

---

### 🛠️ Troubleshooting API Capacity

- Start with your logs: check for throttling, rate limit errors, or slow response times  
- Review monitoring tools:
  - 📊 Compare actual usage to allowed RPS  
  - Watch for usage spikes or abnormal patterns  
- You may need to:
  - Request higher limits (contracted API capacity)
  - Split traffic across multiple endpoints

---

### 🔁 Analogy: Like a Ticket Booth

- An API is like a ticket window at a concert  
- It can serve only so many people per second  
- Too many people = line backs up, people get turned away  
- Your baseline = normal crowd size  
- Your API cap = how fast the window can serve  
---
### 🧱 Bandwidth

Bandwidth is how much data your network can handle at a time — like the width of a highway.

- If bandwidth is too low:
  - 🐢 Network latency increases
  - ❌ App timeouts and degraded performance
  - 😠 Customer frustration (especially in e-commerce)

---

### ✅ What Affects Bandwidth

- Network adapters have different speeds (e.g., 1 Gbps to 100+ Gbps)  
- These speeds should be part of your baseline network metrics  
- For high-speed or low-latency apps:
  - Place VMs in the same placement group  
  - Use high-speed NICs to reduce cross-traffic lag

---

### 🌐 Cloud vs. Private Bandwidth

- In public cloud, bandwidth between the cloud and internet is managed by the provider  
- This link can become a bottleneck if not monitored  
- In private cloud setups:
  - You control bandwidth usage and capacity  
  - 📞 You may need to contact your ISP to upgrade circuits or increase speed  

---

### 📦 Analogy: Like a Freight Tunnel

- Bandwidth = width of the tunnel  
- Data = trucks going through it  
- Too narrow = traffic backs up, delivery delays  
- High-speed adapter = multiple lanes  
- Placement group = trucks starting from same warehouse  

---
### 🧱 Cloud Batch Job Scheduling

Batch jobs are large, scheduled processing tasks — often resource-heavy and time-bound.

- Running batch jobs in the cloud can strain your fleet's compute capacity  
- Underestimating job size leads to:
  - 🐢 Slower execution than expected  
  - 💸 Unplanned capacity purchases  
  - ❌ Job failures if autoscaling doesn’t trigger fast enough  

---

### ✅ Autoscaling Can Help

- Autoscaling adds compute power automatically when job demands spike  
- Helps absorb surprise workloads without manual intervention  
- Important for workloads with unpredictable or seasonal spikes  

---

### 🧩 Database Impact

- Many batch jobs depend on relational databases  
- Running them can stress the DB — especially during:
  - 🔁 Heavy write operations
  - 🧠 Complex queries across large datasets  
- This creates a domino effect of performance issues  

---

### 🛠️ Best Practices

- Ensure your DB server can handle job demand  
- If jobs are read-heavy:
  - Deploy enough read replicas to spread the load  
  - Avoid overloading primary DB with read traffic  
- Monitor database metrics during job execution  

---

### 🏗️ Analogy: Like a Factory Shift

- Think of a batch job as a night shift at a factory  
- If you don’t staff enough workers (compute), production is delayed  
- If too many workers hit the same machine (DB), it overheats  
- Smart scheduling = balancing tasks, machines, and timing  

---
### 🧱 Compute Resources

When creating a VM in the cloud, you define its processing power — usually by setting CPU speed and core count.

- Before migration, measure the processing demand of your current system  
- For new deployments:
  - 📄 Use vendor documentation  
  - 🔍 Review case studies or benchmarks from similar workloads  

---

### ✅ Monitoring CPU Utilization

- Operating systems provide tools to monitor CPU use  
- CPU load should be tracked as part of your baseline  
- Monitoring trends over time helps you:
  - 🧠 Detect performance degradation early  
  - 🔧 Apply fixes before full resource exhaustion  

---

### ⚠️ What to Do When CPU Starvation Hits

- If CPUs are maxed out, you have two main options:

  - **Scale horizontally**  
    - 🧱 Add more servers (VMs)  
    - 🔄 Spread load across multiple instances  
    - ⏱️ Minimal downtime if designed for it

  - **Scale vertically**  
    - 🚀 Upgrade to a higher-tier VM  
    - ⏸️ May require downtime during resize  
    - 🧨 More expensive but stronger individual performance  

---

### 🧠 Analogy: Like a Restaurant Kitchen

- VM = chef  
- CPU = how fast they can cook  
- Too many orders = food delays (performance hits)  
- Horizontal scaling = hire more chefs  
- Vertical scaling = replace your chef with Gordon Ramsay  

---
### 🧱 Network Addressing

IP planning is a capacity issue — once you run out of addresses, your whole deployment can bottleneck.

- Subnet size is defined by the CIDR block  
- CIDR = IP range + subnet mask (e.g., `192.168.0.0/16`)  
- The **smaller** the subnet mask ➝ the **more** IPs available  
  - `10.0.0.0/24` = fewer IPs  
  - `10.0.0.0/8` = many more IPs ✅  
- Always choose a block that allows for future growth, not just current use

---

### ⚠️ You Can’t Always Change Later

- Most cloud providers require you to pick a CIDR block **before** deploying  
- Changing it later may force:
  - 🔄 Redeploying all resources  
  - 🔧 Reconfiguring every IP-dependent device  
- This is disruptive and often not worth it  

---

### 🔐 Reserved IPs

- Some IPs in every CIDR block are **reserved** by the provider  
- Reserved addresses may include:
  - Default gateway (`10.0.0.1` in `10.0.0.0/8`)  
  - DNS and NTP servers  
- These are usually at the **start** of the block  
- 📄 The cloud provider will document which addresses are off-limits

---

### 📦 Analogy: Like a Parking Lot Lease

- CIDR block = size of the parking lot  
- Each IP = parking space  
- Some spaces are always blocked off (reserved)  
- If you run out, you’ll have to tear up the lot and build a new one  

---
### 🧱 Storage Capacity

Storage is one of the fastest-growing cloud resources — usage tends to rise silently until it breaks things.

- Storage volumes have defined size limits  
- Volume utilization should be tracked constantly  
- Set alerts to notify operations when usage passes a threshold (e.g., 80%)  
- If storage fills up:
  - ❌ Applications can crash  
  - 🧨 Data loss may occur  
  - ⛔ Writes may be denied

---

### ✅ How to Handle Storage Capacity

- Use cloud monitoring tools to track volume usage  
- Set automatic alarms and trigger actions at defined thresholds  
- Manage capacity before it reaches 100%  

---

### 🛠️ Resolution Options

- 🪄 If the storage is elastic (like EBS), increase its size  
- 🔄 Migrate data to a larger volume  
- 📦 Archive or clean up unnecessary data  
- 💡 Consider lifecycle policies for object storage (e.g., S3 tiering)

---

### 📦 Analogy: Like a Bookshelf

- Storage volume = bookshelf  
- Files = books  
- When it’s full:
  - You can’t add more  
  - Some books fall off = data loss  
- Solutions:
  - Get a bigger shelf  
  - Add a second shelf  
  - Remove books you no longer read  

---
### 🧱 Variance in Number of Users

User count directly impacts system load — and user spikes can overwhelm cloud services if not planned for.

- Track user metrics as part of your performance baseline  
- Two common patterns to measure:
  - 🧭 Total visitors (web traffic over time)  
  - 🔐 Concurrent logged-in users (session-based apps)  
- Variance tracking helps identify:
  - 🕒 Peak hours
  - 💤 Low activity periods
  - 📈 Growth trends

---

### ✅ Why It Matters

- High concurrent user count = high system load  
- Systems must scale to absorb spikes or throttle gracefully  
- Failure to prepare leads to:
  - ❌ Login errors  
  - 🐢 Slow response times  
  - 💥 Resource exhaustion  

---

### 🛠️ Troubleshooting with User Metrics

- Monitor usage to locate congestion points  
- Map high user periods to infrastructure stress  
- Useful for:
  - Cloud autoscaling triggers  
  - Identifying overused services  
  - Investigating performance slowdowns  

---

### 🔐 Licensing & Limits

- Some identity and access management systems have max user limits  
- Software license models may be based on:
  - Total users  
  - Concurrent sessions  
  - Usage tiers  
- Track user variance to avoid hitting hard limits  

---

### 📦 Analogy: Like a Coffee Shop Rush

- Users = customers walking into the café  
- Each logged-in user = one seated at a table  
- More users than chairs = standing room only  
- You either:
  - Buy more tables (scale infra)  
  - Limit access (throttle or queue)  

---
#cloud-plus  
#compute  
#storage  
#networking  
#api  
#baselines  
#monitoring  
