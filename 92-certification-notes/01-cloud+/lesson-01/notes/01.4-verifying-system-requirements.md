## ‚öôÔ∏è 1.4 Verifying System Requirements: Scaling for Requirements

After conducting a needs analysis and selecting a pilot application, the engineering team must **review the full cloud system design**. This includes:

- Application configuration
    
- Networking setup
    
- Storage design
    
- Security policies
    

Before going live, it's best to **stage the system** in a cloud environment for testing ‚Äî this helps verify performance and functionality.

### ‚òÅÔ∏è Dynamic Allocation in the Cloud

Cloud providers like AWS, Azure, and GCP automatically **scale resources up or down** based on current demand. This is crucial for:

- Reducing idle resources
    
- Handling peak loads
    
- Saving costs
    

This is especially common in **SaaS and PaaS** services. Resources are dynamically added or removed as demand changes.

### ‚öôÔ∏è Elastic & On-Demand Services

- **Elastic computing**: Automatically adjusts the computing power to match your current need.
    
- **On-demand services**: Instantly spin up or tear down cloud resources (VMs, storage, etc.) only when needed. Ideal for:
    
    - Developers testing new builds
        
    - Temporary workloads
        
    - Avoiding unnecessary costs
        

### üí∏ Pay-As-You-Go (PAYG)

- Like a utility (e.g., water, electricity)
    
- You only pay for what you use
    
- No need to pre-provision infrastructure for traffic spikes
    

This model helps avoid overprovisioning and allows for more cost-efficient, flexible growth planning.

Next up: We'll cover how **regions** and **availability zones** impact these requirements and how to plan cloud deployments accordingly.

---
## ‚òÅÔ∏è Cloud Regions and Availability Zones

### üåç Regions

Cloud providers split their global infrastructure into **regions** for:

- **Fault tolerance**
    
- **Local performance**
    
- **Regulatory compliance** (e.g., keeping data inside a specific country)
    

üó∫Ô∏è A **region** is a geographical area like ‚ÄúTokyo‚Äù or ‚ÄúLondon,‚Äù not just one datacenter.

üîó All regions are connected via **high-speed optical networks**, but isolated from each other. So, if one region fails, others continue operating.

üìù When deploying cloud services, you:

- **Choose a region**
    
- May replicate across multiple regions for performance or backup
    

---

### üß± Availability Zones (AZs)

A **region** is broken into **two or more AZs** ‚Äî each being:

- A separate datacenter (or closely grouped buildings)
    
- With **redundant power, networking, and cooling**
    

AZs are:

- Spread apart to reduce shared risk (e.g., earthquakes, floods)
    
- Internally connected with **low-latency, high-bandwidth** links
    

üí° Best practice: Run **redundant VMs** across multiple AZs for high availability.

---

### üß© Cluster Placement

By default, you can run VMs on **different hosts** for redundancy.

But sometimes, you **intentionally group VMs** to run on the same host if:

- They need **extremely low-latency** communication
    
- They must **stay together** due to application design
    

This is known as a **cluster placement rule**.

‚ö†Ô∏è Downside: If that host fails, **everything goes down** ‚Äî so it‚Äôs better to spread across AZs **unless tight latency is required**.

---
## üåê Edge Computing

**Edge computing** brings computation closer to where the data is created ‚Äî at the **‚Äúedge‚Äù** of the network, like a local device or edge server.

### üîß Why it matters:

- Reduces **latency** (faster response time)
    
- Saves **bandwidth** (less data sent to the cloud)
    
- Improves **real-time performance**
    
- Boosts **privacy**, since less sensitive data is transmitted to centralized systems
    

---

### üß† Key Use Cases:

- **IoT devices** (e.g., smart sensors, connected appliances)
    
- **Self-driving cars** (need fast decision-making on the spot)
    
- **Factory automation** (local control of machinery)
    
- **Healthcare devices** (low-latency patient monitoring)
    

---

### üìâ Big Picture Benefits:

- Offloads cloud workloads
    
- Prevents network congestion
    
- Makes apps more reliable and efficient at the edge
    

üß† Think of it like: ‚ÄúWhy wait for the cloud when your device can decide now?‚Äù

---
## üñ•Ô∏è Remote Management of Virtual Machines (VMs)

In the cloud, you **don‚Äôt get physical access** to servers ‚Äî so remote access is your only option. You‚Äôll use tools the cloud provider offers to monitor and control your VMs.

---

### üîß Managing the Hypervisor

- You can‚Äôt directly access the cloud hypervisor (it‚Äôs proprietary)
    
- Instead, you use a **management application** on your local machine that communicates with the hypervisor
    

üñ•Ô∏è Example: A management station with a hypervisor management console can connect to the cloud hypervisor to configure VMs.

---

## üì° Tools for Remote VM Access

### 1. **RDP (Remote Desktop Protocol)**

- Developed by Microsoft to remotely control Windows systems
    
- Lets you interact with a **graphical desktop** of a Windows VM as if you were sitting at it
    
- Uses **TCP port 3389**
    
- Tool: **Remote Desktop Services** (pre-installed on most Windows OS)
    

üß† You use RDP to control Windows-based cloud VMs through a GUI.

---

### 2. **SSH (Secure Shell)**

- Secure, **encrypted command-line** access (unlike Telnet)
    
- Most commonly used for **Linux VMs**
    
- Uses **TCP port 22**
    
- You run commands to configure and control cloud services
    

üß† Think of SSH like a secure terminal into your Linux server in the cloud.

---

‚úÖ Both RDP and SSH are essential tools for managing VMs:

- RDP = GUI access for Windows
    
- SSH = CLI access for Linux
---
## üìà Monitoring and Automation in the Cloud

Creating a working cloud deployment is just the beginning ‚Äî you also need to **monitor and maintain** it to ensure reliability and performance.

---

### üîç Monitoring

Cloud providers give you tools to:

- Track **performance metrics** (e.g., CPU usage, response time)
    
- Monitor **health status** of VMs and apps
    
- Set up **alerts** via:
    
    - Text message
        
    - Email
        
    - Integration with other systems (e.g., Slack, incident management tools)
        

Example: An alert when a VM goes down or app response time slows down.

---

### ü§ñ Automation

Automation lets you:

- **React to monitoring events automatically**
    
- **Autoscale** resources as needed
    

> Example: If VM CPU usage exceeds 98% for 10+ minutes, the system can **automatically add vCPUs** to handle the load.

Cloud automation helps ensure performance and resilience **without human intervention** ‚Äî you just configure the rules and let it run.

---
## üìÑ Documentation in Cloud Deployment

Cloud documentation isn't just about writing things down ‚Äî it's a shared responsibility across multiple teams:

- Server and virtualization teams
    
- Networking and storage
    
- Developers and security experts
    
- Cloud providers themselves
    

üóÇÔ∏è Once it's created, this documentation should:

- Be **easily accessible**
    
- Clearly explain standard operating procedures (SOPs)
    
- Be kept **up-to-date** as cloud systems evolve
    

Some companies even form compliance teams just to make sure documentation stays consistent.

---

## üéØ Creating Baselines for Cloud Performance

Before migration, you need to know your starting point. That‚Äôs where **baselines** come in.

A baseline is a record of normal system behavior ‚Äî CPU usage, memory, network traffic, etc.

### Why you need baselines:

- To detect when a metric **deviates** from the norm
    
- To trigger **alerts** or **autoscaling** based on changes
    
- To see trends over **short-term and long-term** periods
    

üí° Example: If your server averages 70% CPU daily but occasionally spikes to 90% for 15 minutes, you wouldn‚Äôt want alerts firing each time. But if average CPU starts creeping toward 80%, that‚Äôs worth investigating.

> Focus on your **most impactful** metrics ‚Äî not everything at once.

---

## üîÑ Shared Responsibility Model (IaaS vs PaaS vs SaaS)

In the cloud, you're not doing everything alone. **Responsibility is shared** between you and the provider, depending on the service model.

### IaaS (Infrastructure as a Service)

- Provider manages: physical hardware, networking, hypervisors, block storage
    
- You manage: VMs, OS, applications, configurations
    
- ‚ö†Ô∏è Even if they provide a default virtual network, you must still **configure it securely**
    

### PaaS (Platform as a Service)

- Provider manages: everything **under** your app (VMs, OS, storage)
    
- You manage: the apps and services you build
    
- Networking may be pre-configured or customizable depending on the provider
    

### SaaS (Software as a Service)

- Provider manages **everything**, including the app itself
    
- You only manage how you **use** it (e.g., user settings, permissions)
    

Think of it as:

- IaaS = You rent the land and build the house
    
- PaaS = You rent a house and furnish it
    
- SaaS = You rent a hotel room ‚Äî just use it and go
    

---

