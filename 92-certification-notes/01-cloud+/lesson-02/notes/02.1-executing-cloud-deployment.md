### 🔑 Key Concepts

- **Cloud Deployment**
    
    > The act of placing resources _in_ the cloud.
    
    - Example: Spinning up VMs and load balancers.
        
    - Even uploading files to cloud storage counts as a (small) deployment.
        
    - It's about **placing new resources** where they didn't exist before.
        
- **Cloud Migration**
    
    > The process of **moving existing resources** to the cloud.
    
    - Often _not_ literal hardware migration.
        
    - Usually involves **re-creating** the resource in the cloud.
        
    - Example: Rebuilding a DB server in the cloud with new specs and copying data over.
        
    - You often end up with **two versions** temporarily (on-prem and cloud).
        
    - Most migrations aren't just “lift and shift” — they involve **significant rearchitecture**.
        

### 🧠 Main Takeaway

> Migration ≠ Copy-paste  
> Migration is rarely a simple move. It’s more like **rebuilding your existing environment** in a cloud-native way. You'll likely need to **adapt your system architecture** due to differences between your data center and cloud operations.

---
## 🔄 Understanding Deployment and Change Management

### 🚧 What Is Change Management?

**Change management** is the structured process of handling changes, upgrades, repairs, and reconfigurations in cloud services or data centers — with the goal of minimizing disruptions and preventing service failures.

Even if you're not deploying cloud resources for the first time, change management applies **any time** you make updates or new deployments.

---

### 🧱 Key Steps in Change Management:

1. **Submit a change request**
    
2. **Develop an implementation plan**
    
3. **Create a backout plan** (in case things go wrong)
    
4. **Get approvals**
    
5. **Perform the change**
    
6. **Test and validate**
    
7. **Update documentation**
    
8. **Conduct post-change reviews**
    

---

### 🏢 Organization Size & Process

- **Small orgs** may have quick or informal change processes (or none at all).
    
- **Large orgs** often have more rigid, frustrating, but necessary procedures with detailed documentation and approvals.
    

---

### 🔍 Change Coordination Must Include:

- Resources needed for change
    
- People responsible for each task (design, config, validation, etc.)
    
- Coordination across teams
    
- Investigation into dependencies to avoid conflict
    
- Sequencing of changes when one relies on another
    

---

### ⚠️ Real-World Reminder

Change management is **not about bureaucracy**, it’s about **preventing problems**.  
That said, many professionals view it as a hurdle. If the risk is low and properly justified, it's sometimes possible to **bypass strict procedures** with documented approval.

---
### 🏛️ Change Review Group (a.k.a. Change Advisory Board)

- In **medium to large organizations**, a formal **change review group** is responsible for reviewing and approving all pending changes.
    
- Members often include:
    
    - Managers
        
    - Architects
        
    - Stakeholder reps from various departments
        

Their goal is to **catch potential issues** before a change is approved or implemented.

---

### ❓ Key Questions They Ask:

- What do you expect to gain from the change?
    
- What are the risks if we do or don’t implement it?
    
- Which departments are involved?
    
- How long will the change take, including validation?
    
- How long would it take to reverse the change if needed?
    

---

### 🧠 Final Reminder

The review group will evaluate:

- Potential disruption to ongoing ops
    
- Impact on service-level agreements (SLAs)
    
- Unforeseen outages or costs
    

Every change request must be approved, denied, or sent back for revision.

### 🛠️ As Engineers, Our Role in Change Management:

We’re the **technical brains** behind the proposed change — but we’re _not_ the final decision-makers.

Before anything goes live, **we must first ask ourselves the hard questions**, like:

- What’s the actual benefit of this change?
    
- What risks are we introducing?
    
- Which systems and teams will be affected?
    
- How long will this take — and can we undo it if it fails?
    

Once we’ve got clear, honest answers to those questions, we **submit the change proposal** to a review group (like a **Change Review Board** or **Change Advisory Board**).

---

### 📊 Who Makes the Final Call?

Usually, that review group includes:

- Business managers
    
- Architects
    
- Stakeholders from multiple departments (finance, HR, compliance, etc.)
    

They evaluate our proposal _not just from a technical angle,_ but also from a **business risk and operational impact perspective.**

If it passes? ✅ Green light.  
If not? ❌ Back to the drawing board — or they ask for revisions.

--- 
## ⏱️ Setting a Realistic Migration Timeline

### 📋 Why It Matters

A clear, realistic migration timeline is **essential** to reduce the risk of:

- Outages
    
- Failed rollouts
    
- Unforeseen issues requiring rollback
    

Doing migrations **incrementally** gives you room to test, recover, and avoid major disasters.

---

### 🧪 Example: Two-Tier Web App

- Web front-end and backend database hosted in a data center
    
- Migrate only the **front-end** to the cloud first
    
- Users access via a domain name → update DNS to point to new front-end
    
- If something fails, revert the DNS — simple and fast
    
- This lets you "test in production" with minimal user disruption
    

---

### 🔧 Use Maintenance Windows

Even “safe” migrations should be done during a **maintenance window**, where:

- Downtime is expected and planned
    
- Stakeholders are aware
    
- Risk is minimized
    
- Engineers have breathing room
    

Many outages happen because people skip this step — don’t.

---

### 🧠 Plan for Everything

The migration time window must include:

- Setup and execution time
    
- Testing and validation time
    
- Stakeholder sign-offs
    
- Extra buffer in case of rollback
    

If you need to **bring the original system back online**, you’ll be glad you budgeted the time.

### 🕸️ **What Is a Web Front-End and Back-End?**

- **Front-End** = what the **user sees and interacts with** (like the website’s buttons, forms, and pages)  
    💻 Example: Login screen, shopping cart, dashboard, etc.
    
- **Back-End** = what runs **behind the scenes** (servers, databases, APIs that process your input)  
    🗄️ Example: Saving your order to a database, handling logins, fetching your profile info.
    

---

### 🧱 What Does "Two-Tier" Mean?

- **Tier** = layer or part of a system.
    
- A **two-tier architecture** means there are **two main parts**:
    
    1. **Client/UI Layer (Front-End)**
        
    2. **Database or Logic Layer (Back-End)**
        

🔁 These layers talk to each other — but are _separate_. You can move or upgrade one without touching the other.

---

### 🌐 What Is DNS?

**DNS = Domain Name System**

- It's the internet's **phonebook** — it maps **domain names** (like `google.com`) to **IP addresses**.
    
- When a migration happens, instead of telling users a new IP address, you just **update the DNS** record to point your domain to the new server.
    

🛠️ In a migration:

- You move the front-end to the cloud
    
- Leave the back-end in your data center
    
- Just update the DNS so your domain points to the new cloud server
    
- If something breaks? Change DNS back — and boom, you’ve “rolled back” the change.

---

## 📚 Documenting and Following Procedures

### 🧩 Why Documentation Matters

Accurate, current documentation is critical to a successful cloud migration.  
You need to:

- Know **exactly what you're starting with**
    
- Review/update current documentation
    
- Maintain **diagrams, backups, and configs**
    

Sources include:

- Network monitoring tools
    
- Device configs
    
- Vendor docs
    
- Change logs
    

---

### 🔄 Pre vs. Post-Migration Docs

- Expect **major differences** between data center and cloud architectures
    
- There’s no 1-to-1 match for every component
    
- You’ll end up with **two sets of docs**:
    
    - Before migration
        
    - After migration
        

---

### 📎 What to Document:

- IP addresses (internal + public)
    
- Routing tables
    
- Firewall rules
    
- VPNs, load balancers, proxies
    
- Ports, protocols
    
- Access rules and ACLs
    
- Network diagrams (subnets, connections, routing paths, etc.)
    
- Redundancy + rollback plans
    
- Interconnects between data centers and cloud
    

---

### 🔧 IaC = Built-In Docs

Coming in Lesson 5: **Infrastructure as Code (IaC)**

- IaC templates = pre-written documentation
    
- No need to re-document everything manually
    
- Still update diagrams for human clarity
    

---

### 🗺️ Diagrams & Maps Are a Must

- Core network maps = the big picture
    
- Redundancy maps = backup systems and failovers
    
- Access/distribution network diagrams = VPNs, corporate links, access control, cloud perimeter
    

---

### 🧠 Pro Tip

Use **network mapping tools** (some are built into cloud platforms)  
They:

- Auto-detect topology
    
- Create updated diagrams
    
- Help with **ongoing capacity planning + troubleshooting**
    

---

### 🎯 Final Takeaway

Documentation = your **roadmap** for migration and your **lifeline** when things go sideways.  
Treat it as critical, not optional.

### 🧠 Personal Understanding:

From what I’ve learned, **thorough documentation** is one of the most important parts of:

- ✅ **Change Management** – so you know exactly what’s being changed, why, and how to reverse it if needed.
    
- ✅ **Cloud Migrations** – especially when transferring to another provider where architecture may differ.
    
- ✅ **Troubleshooting** – if something breaks, clear diagrams and config records can save hours of guesswork.
---
## 🔄 What Is a Cloud Workflow?

A **cloud workflow** is a **series of steps or activities** needed to complete a task. Cloud providers offer workflow services to help manage and track these steps — especially when a project has multiple moving parts.

---

### 🛒 Example: E-Commerce Workflow

An online store has many steps in a transaction:

- Shopping cart
    
- Checkout
    
- Payment processing
    
- Warehousing
    
- Shipping
    

Each of these tasks has **preconditions** and **post-conditions**, and they’re often triggered by **external events** (like a user placing an order).

---

### ☁️ Cloud Workflow Services Handle:

- Human processes (e.g., approvals)
    
- Parallel processes (e.g., shipping + invoicing)
    
- Sequential tasks (e.g., payment → confirm order → ship)
    

🧠 **Think of a cloud workflow as a “state tracker”** that helps coordinate everything in a system or migration.

---

### 🧠 Key Insight

The **same concept** applies to cloud migration:

- Each step in the migration process can be modeled in a workflow
    
- Project managers and engineers use workflows to **design**, **track**, and **validate** every phase
    

It brings structure and visibility to complex cloud operations.

### 🧠 Understanding Cloud Workflows (Simplified)

Think of a **cloud workflow** like an **automated to-do list** — but way smarter.

Each step happens in a **specific order**, or based on **conditions**.  
Just like ordering from Amazon — you don't get the package until:

1. You add items to your cart
    
2. You check out
    
3. You pay
    
4. The system processes the order
    
5. Warehouse receives the request
    
6. It ships to your address
    

All of those are steps in a **workflow** — and most of them happen **automatically**, once the first one starts.

---

### 🛠️ Cloud Workflow = Smart Automation Engine

- A **cloud workflow system** watches over all the steps
    
- It tracks what’s been done, what’s in progress, and what comes next
    
- If one step fails, it can stop the rest or alert someone
    
- If steps can happen **at the same time** (parallel), it handles that too
    

---

### 🛠️ In Migration or DevOps

In a **cloud migration** or CI/CD pipeline:

- Step 1: Backup
    
- Step 2: Provision servers
    
- Step 3: Deploy app
    
- Step 4: Test
    
- Step 5: Notify team
    

This can all be wrapped in a **workflow** that:

- Runs automatically
    
- Logs every step
    
- Sends alerts if anything breaks
    
- Makes sure steps happen in the right order
    

---

### 🔁 Summary:

> A **workflow** is the cloud’s version of an organized “if-this-then-that” system.  
> It brings automation, order, and tracking to complex tasks — whether you're processing orders or deploying infrastructure.

### 🧠 My Understanding of Cloud Workflows (Personal Insight)

A **cloud workflow** is basically a long-running, automated process that tracks each step in a sequence. It updates itself as things get completed or triggered.

When something is **finished**, **fails**, or **needs attention**, the workflow:

- **Updates the state** of the process
    
- **Triggers alerts** (emails, dashboards, logs, etc.)
    
- **Moves to the next step** (if conditions are met)
    
- Or **pauses** if something is missing or broken
    

This is super useful in **cloud migration** or **DevOps pipelines** where:

- You need visibility
    
- You want tasks to run automatically
    
- And you need to **know exactly where things are in the process**
    

In other words:

> A cloud workflow keeps track of the action and speaks up when something changes. 👀✅⚠️

---
## ⚙️ Setting Up Your Cloud for Automation

### 🔧 What Is Cloud Automation?

Cloud automation is a **core part of modern cloud infrastructure**.  
It means using tools and scripts to automatically:

- Deploy resources
    
- Manage configurations
    
- Monitor and respond to system events
    
- Scale systems up or down based on load
    

Automation is offered by cloud providers through:

- Web dashboards
    
- APIs (Application Programming Interfaces)
    
- SDKs (Software Development Kits)
    
- CLI tools (Command-Line Interfaces)
    

---

### 🌐 Hybrid & Multi-Cloud Automation

Vendors also offer **global cloud management systems** that:

- Work across multiple cloud providers
    
- Help manage hybrid cloud setups
    
- Let you automate **from one central place**
    

---

### 🔍 Key Point:

> Automation is a **deep and complex** topic — deeper than the Cloud+ exam dives — but knowing the types of automation tools and where they apply is critical.

---

### 🧠 Personal Insight: Cloud Workflow & Automation

I understand cloud workflows now as **real-time trackers** of processes — kind of like automated status updates.  
When something **starts, finishes, or breaks**, the workflow system:

- Updates the progress
    
- **Sends alerts**
    
- Triggers the **next automated step**
    
- Or waits for input before continuing
    

This is **exactly** what you’d want in a long process like:

- A multi-step app deployment
    
- A full cloud migration
    
- Or even processing an online order with dozens of steps

---
## 🛠️ What Are Cloud Tools and Management Systems?

### 📡 Why They Matter

Managing and monitoring your cloud deployment is _just as important_ as deploying it.  
Once everything is up and running, you need tools that:

- Watch system performance
    
- Catch faults or security issues
    
- Automate scaling or alerting
    
- Maintain uptime and SLAs (Service Level Agreements)
    

---

### 📊 What Can Be Monitored?

You can track:

- CPU, memory, disk usage
    
- Network traffic and interface stats
    
- Logs from apps, servers, services
    
- VPNs, firewalls, storage, load balancers, etc.
    

Many cloud providers allow you to **automate reactions** to metrics.

> Example: If CPU hits 95%, automatically launch more instances.

---

### 🏢 Network Management Overview

- Network management involves many **monitoring systems**
    
- These report to a **Network Management Operations Center**
    
- They cover both **on-prem** and **cloud** infrastructure
    
- The architecture often includes:
    
    - Monitoring systems
        
    - Core data networks
        
    - Cloud/corporate data centers
        
    - A central control/operations team
        

---

### ☁️ FCAPS Management Model

The FCAPS acronym summarizes the **five core areas of cloud/network management**:

|Letter|Area|What It Covers|
|---|---|---|
|**F**|Fault|Detecting and resolving errors or outages|
|**C**|Configuration|Setting up and maintaining correct configs|
|**A**|Accounting|Tracking usage, cost, and resource allocation|
|**P**|Performance|Ensuring speed, availability, efficiency|
|**S**|Security|Protecting systems, users, and data|

---
## 🧾 Configuration as Code (CaC)

### ⚙️ What Is It?

**Configuration as Code (CaC)** is the practice of turning infrastructure setup into **machine-readable code** (scripts or templates) to ensure consistency, speed, and repeatability.

Instead of configuring each system manually:

- You write a config file once
    
- Then deploy it automatically
    
- It’s **version-controlled**, **auditable**, and **reusable**
    

---

### ✅ Benefits of CaC:

- Reduces human error
    
- Speeds up deployments
    
- Makes infrastructure **uniform across environments**
    
- Changes can be tracked and rolled back
    
- Supports DevOps practices and automation pipelines
    

---

### 🔧 Common CaC Tools:

- **Terraform** – cloud-agnostic, uses HCL
    
- **Ansible** – agentless automation using YAML
    
- **AWS CloudFormation** – native to AWS, uses JSON/YAML
    
- Others: Puppet, Chef, Pulumi
    

---

### 🧠 Personal Understanding:

> This reminds me of writing `.bashrc` or `.zshrc` config files, where a few lines of code define how my system behaves every time it starts.  
> Now imagine that same idea applied to entire **servers, networks, and apps** — that's what CaC is doing, but at cloud scale.

---
## ⚖️ Resource Allocation

### 📦 What Is It?

**Resource allocation** is the process of distributing compute power, memory, storage, and bandwidth across systems in a way that:

- Prevents bottlenecks
    
- Enhances performance
    
- Maximizes hardware utilization
    
- Balances cost and efficiency
    

---

### 📈 Key Concepts:

- **Dynamic allocation** adjusts resources in real time based on demand
    
- Helps cloud systems **scale automatically**
    
- Enables **cost savings** and **flexibility**
    
- Critical for apps that have **fluctuating traffic** (e.g., e-commerce, streaming)
    

---

### 🧠 New Trends in Allocation:

- **Machine learning-based forecasting** helps predict resource needs before they spike
    
- **Container orchestration** (like Kubernetes) distributes workloads across servers
    
- **Virtualization** keeps systems modular and scalable
    
- These tools make sure nothing is underused or overwhelmed
    

---

### 🎯 Why It Matters:

> A smart allocation strategy means you're not overpaying for idle servers or crashing under heavy load. It’s about **right-sizing** resources to keep your cloud systems reliable, efficient, and fast.

---
## ☁️ Cloud Deployment Models

There are several different **deployment models** used to deliver cloud services, each with its own level of control, cost, and security.
### 🌍 Public Cloud

- **Hosted and managed by third-party providers**
    
- Shared across multiple organizations (tenants)
    
- Scalable and cost-effective, but less customizable
    
- Example: AWS, Microsoft Azure, Google Cloud Platform
    

>   
> _Multiple Organizations Sharing a Cloud Service_

---

### 🏢 Private Cloud

- **Dedicated to a single organization**
    
- Can be hosted on-premises or by a third-party provider
    
- Offers more control, customization, and security
    
- Usually uses **dedicated hardware**
    

>   
> _Used by a Single Organization_

---

### 🔀 Hybrid Cloud

- Combines **two or more** cloud types (e.g., public + private)
    
- Used for **load balancing**, **cloud bursting**, or **regulatory separation**
    
- More flexible, but more complex to manage
    

>   
> _Combination of Cloud Services_

---

### 🏛️ Community Cloud

- Shared by **organizations with common interests or compliance needs**
    
- Used by sectors like:
    
    - Healthcare
        
    - Banking
        
    - Nonprofits
        
    - E-commerce
        
- Can be managed by one or more organizations, providers, or third parties
    

>   
> _Shared for Common Needs or Industries_

---
## 🌐 Network Deployment Considerations

### 📌 Key Idea:

Cloud networking works **differently** from traditional on-prem data centers.  
Most network functions still exist — but they’re:

- **Abstracted** (hidden from direct access)
    
- Managed through the **cloud provider’s interface**
    
- Not something you can “log into” like a physical switch or router
    

---

### 🔍 Key Differences:

- Traditional networks:
    
    - You manage **physical devices** like switches, routers, and firewalls
        
    - You directly configure them
        
- Cloud networks:
    
    - These devices are **virtualized and managed by the provider**
        
    - You use a web dashboard, CLI, or API to define behavior
        
    - You don’t have access to the underlying infrastructure
        

---

### 🧠 Personal Tip:

> When planning a cloud deployment, don't expect to configure networks like you would on-prem. You're working with **virtual constructs**, not physical gear.  
> Always consider the **limitations** and **control boundaries** of your cloud provider’s platform.

---
## 🌐 Network Protocols

These are some of the most common protocols you’ll encounter while configuring networks and firewalls, especially in cloud environments. Knowing their default ports and usage is essential.

---

### 🌍 HTTP & HTTPS:

- **HTTP (Hypertext Transfer Protocol)**:
    
    - Port: **TCP 80**
        
    - Used by web browsers to access websites in the cloud.
        
- **HTTPS (Hypertext Transfer Protocol Secure)**:
    
    - Port: **TCP 443**
        
    - Secures HTTP with **TLS (Transport Layer Security)** to protect data during transit.
        

---

### 📂 FTP & FTPS:

- **FTP (File Transfer Protocol)**:
    
    - Port: **TCP 21**
        
    - Used for transferring files between systems.
        
- **FTPS (File Transfer Protocol Secure)**:
    
    - Ports: **TCP 989, 990**
        
    - Encrypted version of FTP using **TLS**.
        

---

### 🔑 SSH & SFTP:

- **SSH (Secure Shell)**:
    
    - Port: **TCP 22**
        
    - Encrypted alternative to Telnet for remote device access via command-line.
        
- **SFTP (Secure File Transfer Protocol)**:
    
    - Port: **TCP 22** (same as SSH)
        
    - FTP over SSH for **secure file transfers**.
        

---

### 🌍 DNS:

- **DNS (Domain Name System)**:
    
    - Port: **UDP 53**
        
    - Resolves domain names (like `example.com`) to IP addresses, routing web traffic.
        

---

### 🖧 DHCP:

- **DHCP (Dynamic Host Configuration Protocol)**:
    
    - Port: **UDP 68**
        
    - Automatically assigns IP addresses to devices on a network.
        

---

### 📧 SMTP:

- **SMTP (Simple Mail Transfer Protocol)**:
    
    - Port: **TCP 25**
        
    - Sends emails between mail servers.
        

---

### ⏰ NTP:

- **NTP (Network Time Protocol)**:
    
    - Port: **UDP 123**
        
    - Syncs system clocks with authoritative time sources, important for **logging accuracy** and **security**.
        

---

### 📋 Summary:

Knowing these protocols, their ports, and functions is crucial for setting up secure and well-functioning cloud networks, especially when configuring firewalls or networking rules.

---
## ⚙️ Network Ports

### 🔑 What Are Network Ports?

Network ports are used by applications to identify and access services. Each application typically uses a **well-known port number** to communicate through the network. These ports are used to direct traffic to the correct service on the remote server.

---

### 🌐 Common Well-Known Ports:

- **TCP Port 80** – **HTTP** (Hypertext Transfer Protocol), used for web traffic (World Wide Web).
    
- **TCP Port 21** – **FTP** (File Transfer Protocol), used for transferring files between systems.
    
- **TCP Port 25** – **SMTP** (Simple Mail Transfer Protocol), used for sending emails between mail servers.
    
- **TCP and UDP Port 53** – **DNS** (Domain Name System), used for domain lookups and translating domain names to IP addresses.
    
- **TCP Port 443** – **HTTPS** (Hypertext Transfer Protocol Secure), used for secure web traffic (SSL/TLS encrypted).
    
- **UDP Ports 67, 68, 546, 547** – **DHCP** (Dynamic Host Configuration Protocol), automatically assigns IP addresses to devices. IPv4 uses ports **67** and **68**, and IPv6 uses **546** and **547**.
    

---

### 🧠 Key Point:

When you type a URL like `https://www.comptia.org` into your browser, it’s automatically trying to connect to **port 443** (HTTPS). The browser sends this information in a **TCP/IP packet**, and when it reaches the server, the server knows to process it as an encrypted HTTPS request.

---
---

## 🌐 Network Configurations

### 🛠️ What Can Be Configured?

While cloud providers manage the **physical networks** within their data centers, **you** can configure your own **virtual networks** on top of those.

#### What Can You Configure?

1. **Routes** — Decide how network traffic moves between resources.
    
2. **Access Control Lists (ACLs)** — Set rules about which traffic is allowed or denied.
    
3. **Security Groups** — Define security policies for cloud resources.
    
4. **IP Address Assignment** — Manage which IP addresses are used by different resources.
    

#### Other Network Services:

- **Load Balancers** – Distribute traffic across multiple servers to improve availability and reliability.
    
- **Application (Layer 7) Firewalls** – Filter traffic based on specific application protocols.
    
- **Content Delivery** – Ensure fast content distribution across geographies.
    
- **Caching Systems** – Store frequently used data for faster access.
    
- **DNS Services** – Map domain names to IP addresses to make resources accessible.
    

---

### 🧠 Personal Understanding:

> Configuring networks in the cloud feels like setting up a **digital city**, where routes are streets, firewalls are walls around important buildings, and IP addresses are the street addresses for resources to live. The provider builds the city grid, but **you** determine how everything inside interacts.

---
## 🔒 Virtual Private Networks (VPNs)

### 📡 What Are VPNs?

**VPNs** allow you to create a **secure, encrypted connection** over insecure networks like the internet. They are used to connect remote users or locations to the cloud in a **private, secure tunnel**.

---

### 🖥️ Types of VPNs:

1. **Point-to-Site VPN** (Remote Access VPN):
    
    - Used when a **single user** (like an employee at home) connects securely to the cloud.
        
    - Each user has an encrypted connection to the cloud data center.
        
2. **Site-to-Site VPN** (or Point-to-Point VPN):
    
    - Used to **connect multiple locations** (e.g., branch offices) securely over the internet.
        
    - It’s like connecting two remote locations directly to each other over a secure tunnel.
        

---

### 🔑 Why VPNs Are Important:

- VPNs ensure **secure communication** over public networks like the internet.
    
- They’re essential for **encrypted access** to cloud resources without relying on physical, dedicated connections.
    

>   
> _A VPN creates a secure tunnel over an insecure network like the Internet._

---

### 🔧 VPN Configurations:

There are many **types** of VPNs, ranging from software running on a **client computer** to dedicated VPN concentrators. The setup can get complex, but **in basic terms**, it's about **encrypting traffic** and securely routing it through the internet.

---
## 🔥 Firewalls and Microsegmentation

### 📡 What’s Different About Firewalls in the Cloud?

In a **traditional data center**, firewalls are easy to spot. They’re physical appliances that **restrict traffic** between network segments or subnets.

In the **cloud**, however, firewalls **aren’t visible** — and it can seem like there are none.  
But this isn’t true; firewalls still exist, they’re just **virtualized** and managed through the cloud provider’s interface.

---

### 🔒 Microsegmentation

In the cloud, **microsegmentation** is used to overcome the limitations of traditional firewalls. Rather than applying firewall rules at the subnet level (like in the data center), you can apply them to **specific resources**, such as virtual machines (VMs).

> **Example**: Apply firewall rules to all database VMs, regardless of the subnet they’re in.  
> Microsegmentation allows for **granular control** over traffic at the **network interface level**.

---

### ⚙️ Configuring Firewall Rules

Firewall rules in the cloud can be applied to **two primary places**:

1. **Interfaces**: These are the rules applied to the network interface of a VM.
    
    - These are sometimes referred to as **security groups**, which are similar to **access control lists (ACLs)** in the data center.
        
2. **Networks**: Rules applied to the entire virtual network (or subnet).
    
    - These rules are sometimes referred to as **network security groups**.
        

---

### 🔄 Stateful vs Stateless Firewalls

- **Stateful Firewalls**:
    
    - Allow return traffic automatically.
        
    - **Example**: When a VM requests an update from the internet, the firewall allows the return traffic from that server back to the VM.
        
- **Stateless Firewalls**:
    
    - Don’t automatically allow return traffic.
        
    - You need to create a specific rule for this.
        
    - Generally **broader** and less restrictive than stateful firewalls.
        

---

### 🛡️ Key Takeaways:

- **In the cloud**, firewall rules are managed **virtually**, and they follow resources like VMs wherever they go.
    
- **Microsegmentation** gives you **granular security** at the VM level, **not just the subnet level**.
    
- Cloud firewalls are **virtual appliances** and don't behave the same way as on-prem firewall

### 🔥 Firewalls in the Cloud — Traditional vs. Virtual

1. **Traditional Firewall** (On-Prem)
    
    - **Easy to notice** — physical device
        
    - **Applied broadly** to entire subnets or networks
        
    - **Simple to manage**: You know where it is and how it’s configured
        
2. **Cloud Firewall** (Virtual)
    
    - **Not as visible** — it’s managed virtually through the provider’s interface
        
    - **More flexible**: Rules can be **applied with granular control** to individual resources, like specific **VMs** or network interfaces
        

---

### 🔑 Granular Control vs. Broad Control

- **Granular Control**: You can define **specific firewall rules** for **individual VMs** or even **network interfaces**. You can apply security settings to things like **web servers**, **databases**, etc.
    
    > Example: You can have **different firewall rules** for the **database VMs** and **web VMs** in the same subnet.
    
- **Broad Control**: Firewalls can be set up for larger **subnets**, controlling traffic for all resources within that subnet.
    

---

### 🔄 Stateful vs Stateless Firewalls

- **Stateful Firewalls**:
    
    - **Automatically allow return traffic** — tracks the state of connections.
        
    - Best for **VMs that need to establish connections** to outside resources (e.g., downloading updates).
        
- **Stateless Firewalls**:
    
    - **Doesn’t automatically allow return traffic** — requires explicit rules for both inbound and outbound traffic.
        
    - Typically used for **broader traffic control** at the network level, less granular.
        

---

### 🧠 Your Personal Firewall Setup

- You could set up **stateful firewalls** for **VMs** that require outgoing traffic to external services (like updating software).
    
- For **isolated services** that only need to interact within a closed network, you might use **stateless firewalls**, applying stricter rules to control **who can connect** and what traffic can go through.

---

## 🔐 Web Application Firewalls (WAF)

### 🛡️ What Is a WAF?

A **Web Application Firewall (WAF)** is a specialized firewall designed to monitor **HTTP(S) traffic** and protect your web applications from **exploits**, including **denial-of-service (DoS)** attacks and unauthorized access.

---

### 🕵️‍♂️ How WAF Works:

- **Monitors HTTP(S) requests** for malicious patterns like:
    
    - **Injection attacks** (e.g., SQL injection)
        
    - **Malicious scripts**
        
    - **Suspicious query strings**
        
- **Blocks harmful requests** before they reach the application, acting like a shield.
    
- Can also:
    
    - Filter traffic based on **geographic location**
        
    - Block traffic from **known malicious IP addresses**
        

---

### 🌐 WAF in the Cloud:

- **Cloud providers** offer WAFs as managed services.
    
- Some providers allow you to **spin up a VM** and place the WAF in front of your application.
    

---

### ⚠️ Why Use a WAF?

- While applications can never be **100% secure**, WAFs help protect applications by:
    
    - Blocking known vulnerabilities
        
    - Shielding against attacks you might not have had time to patch yet
        

> **Note**: Even secure applications **must be maintained** against evolving threats. WAFs add a **layer of protection** to patch gaps.

---
## 🔧 Application Delivery Controllers (ADC)

### 🏢 What Is an ADC?

An **ADC** is a **one-size-fits-all network device** designed to streamline managing network traffic by consolidating several functions into a single device.

Rather than configuring and managing **multiple appliances** (like a firewall, WAF, load balancer, etc.), an ADC combines them, making it easier to **manage and optimize** web applications.

---

### 🔄 How Does It Work?

1. **Firewall** filters incoming traffic and allows only **HTTPS** (TCP port 443).
    
2. **WAF (Web Application Firewall)** inspects the traffic for **malicious requests**.
    
3. The **traffic** is then passed to a **load balancer**, which directs it to the appropriate **web server**.
    

If **any** device in the chain is misconfigured, it can cause the entire application to fail.

---

### 🌐 ADC Advantage:

- **Reduces complexity** by combining functions (WAF, firewall, load balancing) into a single device.
    
- **Fewer points of failure**, which means less worry about connectivity between devices.
    

---

### 🧠 Key Insight:

> Think of an ADC as the **central hub** for securing, optimizing, and managing all incoming network traffic for your cloud apps. Instead of juggling several devices, ADC does it all — and **simplifies your setup**.

---
### 🚫 Intrusion Prevention Systems (IPS)

- **Purpose**: IPS is an advanced version of IDS that can also take action.
    
- **How It Works**:
    
    - IPS not only detects suspicious traffic but also **actively mitigates** attacks.
        
    - It **automatically configures routers/firewalls** to block malicious traffic and prevent attacks in real-time.
        

>   
> _IPS monitors activity and automatically applies network rules to prevent attacks._

---

### 🧠 Key Takeaways:

- **IDS**: Alerts about suspicious activity — **no action** is taken.
    
- **IPS**: Both **detects** and **blocks** attacks by automatically modifying firewall/router rules to mitigate the threat.

---

## 🛡️ Demilitarized Zone (DMZ)

### 🌍 What Is a DMZ?

A **DMZ** is a segment of a network that holds **servers** that need to be **accessible both externally (via the internet)** and internally within a private network.

- Common **DMZ servers** include:
    
    - **Web servers**
        
    - **Mail servers**
        
    - **FTP servers**
        
    - **DNS servers**
        

---

### 🔑 Why Use a DMZ?

- **Access Control**: Servers in the DMZ are accessible to the **outside world**, but they **don’t have full access** to the internal network.
    
- **Security**: By isolating these servers in the DMZ, if one is compromised (e.g., a web server), it limits the attacker's ability to access sensitive **internal resources**.
    
- **Firewall Configuration**: Firewalls are configured to allow very specific **traffic** to pass from the outside world to the DMZ, and only limited **internal access** to these servers.
    

---

### 🔄 Example:

Imagine you have an **Internet-facing web server** in the DMZ. The web server might need access to an internal **database server** on a specific protocol or port. If the web server is compromised, the attacker will **not be able to access** other internal resources (like sensitive databases), thanks to the DMZ's isolation.

---

>   
> _DMZ servers are accessed by both the outside world and the internal network._

---

### 🧠 Key Insight:

> The DMZ acts like a **buffer zone** between your secure internal network and the **untrusted external world**, ensuring that web-facing resources have **limited** access to critical internal resources.

### 🛡️ What Is a **Demilitarized Zone (DMZ)?**

A **DMZ** is like a **"buffer zone"** between your **secure internal network** (like your company's private network) and the **outside world** (the internet). It’s a **separate network area** where you place servers that need to be accessed both **internally** (by your organization) and **externally** (by people on the internet).

---

### 🔑 Why Is the DMZ Important?

- **Keeps your internal network safe**:  
    The servers in the **DMZ** (like web servers, mail servers) are **exposed to the internet** and could be targeted by attackers. If one of these servers is compromised, the attacker **can’t easily access** your sensitive internal resources (like databases or file servers). The **DMZ protects** those from direct attacks.
    
- **Controlled access**:  
    The DMZ is carefully controlled by firewalls and only allows certain traffic from the outside (internet) and from the inside (internal network) to reach the servers in the DMZ.
    

---

### 🔒 How Does the DMZ Work?

1. **Web Server Example**:  
    Let’s say you have a **web server** in the DMZ to host your company’s website. People from the internet can access this server when they visit your website.
    
2. **Internal Access Control**:  
    Now, your web server may need to **access an internal database server** to show information on the website (e.g., a product database). The firewall in the DMZ allows that specific **traffic** from the web server to the database server, but **only on specific ports and protocols**.
    
3. **Limiting Damage from Attacks**:  
    If an attacker manages to compromise the **web server** in the DMZ, they **cannot access** your **internal systems** because of the firewall rules. So, even though the web server is publicly accessible, it is **isolated** from your sensitive internal network.
    

---

### ⚙️ Firewall Configuration in the DMZ

- The **firewall** plays a key role in controlling what’s allowed in and out of the DMZ.
    
- The firewall lets **external requests** (such as HTTP requests for a web server) reach the **DMZ**, but it blocks any requests that would let the attacker move from the DMZ to the **internal network**.
    
- It’s a **one-way street** for security: only very **specific traffic** is allowed from the outside to the DMZ or from the DMZ to the internal network.
    

---

### 🧠 Example in Simple Terms:

- Think of the **DMZ** as a **secure lobby** where only specific visitors (internet users) are allowed to check in (access the public server).
    
- If someone tries to get into the **private rooms** (internal network), they **can’t get past the locked doors** because the DMZ acts as a barrier, and there are strict rules to control who can go where.
    

---

### 🎯 The Main Goal:

The **DMZ** essentially makes sure that **public-facing resources** (like web servers) are **isolated from your private resources** (like sensitive databases). If a **server in the DMZ is compromised**, the **attack won’t spread** easily to other parts of the internal network.

---
## 🌐 VXLAN (Virtual Extensible LAN)

### 🧐 Why VXLAN Was Created:

- Traditional Ethernet networks face limitations when you try to scale them up. Ethernet generally supports up to **4,094 VLANs** (Virtual LANs).
    
    - This was fine for small networks, but **cloud providers** need to support **hundreds of thousands** of customers and their **segmented networks**.
        
    - With **4,094 VLANs**, traditional Ethernet networks quickly **hit a limit**.
        

---

### 🔑 What VXLAN Does:

- **VXLAN** extends the traditional VLAN network and provides a solution for:
    
    - **More scalability**: **16 million** unique virtual networks (VLANs) instead of 4,094.
        
    - **Better isolation**: Helps with customer **network segmentation**.
        
- VXLAN works by **encapsulating Ethernet frames** (which are the standard network packets) inside a VXLAN packet. This extra **VXLAN header** includes a **VNI** (VXLAN Network Identifier).
    
    - The **VNI** allows traffic to be **segregated** between different virtual networks.
        

---

### 💡 How It Works:

1. **VLAN** gives you **4,094** subnets.
    
2. **VXLAN** gives you **over 16 million subnets**.
    
3. **VNI (VXLAN Network Identifier)** differentiates each virtual network inside the VXLAN.
    
4. VXLAN allows creating **layer 2 tunnels** over **layer 3 networks**, so it’s easier to **move virtual machines (VMs)** across different geographic locations **without changing their IP address**.
    

---

### ⚠️ Caution: Split-Brain and Network Issues

- **Stretching VLANs** across networks can create **split-brain scenarios** (where data gets out of sync or inconsistent between two sites).
    
- While VXLAN is useful for VM **mobility** and **large-scale network segmentation**, it should be used carefully to avoid problems.
    

---

### 🧠 Key Insight:

> **VXLAN** is like **"supercharging" VLANs** by increasing the number of available virtual networks to meet the demands of large-scale cloud deployments.

### 🧩 What the VNI Does in VXLAN:

The **VXLAN Network Identifier (VNI)** is like a **label or tag** that tells the network which **virtual network** a packet belongs to. It allows **segregation** (separation) of traffic between different tenants or systems **even if they’re using the same IP ranges**.

#### 💥 Why this matters:

- Say you have **two customers**, both using `10.1.0.0/16` as their private subnet.
    
- Without VXLAN, this would **conflict** — the traffic could get mixed up.
    
- With VXLAN, each customer gets a **unique VNI**.
    
- That VNI ensures their data is **completely isolated**, even if the IP addresses look identical.
    

---

### 🔄 In simple terms:

> The **VNI separates one big network** into **many secure, isolated mini-networks**, making the traffic **organized**, **secure**, and **efficient** — especially in huge cloud environments.

---
### 🌀 GENEVE – What it _doesn't_ do:

GENEVE is more chill.  
It **only** defines the **packet structure** (like, how to package the data) — but it says:

> “You figure out the route, boss. I’m just here to carry your stuff.”

That means GENEVE is **more flexible** and future-proof.  
You can pair it with **any control plane** (e.g., EVPN, static routes, whatever floats your boat).

---

### 💡 Quick Analogy:

- **VXLAN** is like Uber **with the driver AND the route pre-decided**.
    
- **GENEVE** is like FedEx saying, “Here’s the box. You decide how to get it delivered.”
    

---

### 📬 Bonus Tip:

- VXLAN uses **UDP port 4789**
    
- GENEVE uses **UDP port 6081**

---
## 🧠 **IP Address Management (Cloud Edition)**

### 📦 **RFC 1918 Private IP Address Blocks**

These are non-routable IPs used **inside** your network (not visible on the internet). Here’s the cheat sheet:

| Block Size       | IP Range                        | # of Addresses |
| ---------------- | ------------------------------- | -------------- |
| **/8** (24-bit)  | `10.0.0.0 – 10.255.255.255`     | 16,777,216     |
| **/12** (20-bit) | `172.16.0.0 – 172.31.255.255`   | 1,048,576      |
| **/16** (16-bit) | `192.168.0.0 – 192.168.255.255` | 65,536         |
Use these inside VPCs, subnets, and internal devices. **No public access unless routed or NAT’d.**

---

### 🚦 **Why Private IPs Matter**

1. **Saves Public IP Space** – IPv4 is limited.
    
2. **Better Security** – Internal-only access means fewer attack vectors.
    
3. **Custom Network Control** – Use firewalls, ACLs, and subnets for flow control.
    

---

### ⚠️ **Avoid Reusing IPs**

**Don't reuse** the same private IP ranges in the cloud that you're using on-prem. Why?

- It'll create **conflicts** when you connect cloud ↔ data center.
    
- You’ll end up debugging weird traffic issues and hating life.
    

---

### 🌐 **When Do You Need a Public IP?**

Use it only when a VM/resource must be **reachable from the internet**, like:

- A **web server**
    
- A **load balancer** pointing to multiple servers
    
- A **bastion host**
    

You can assign a **public IP**, or in many providers (like AWS), use an **elastic IP** (public, but can be re-assigned to different instances as needed).

---

### ✅ **Summary Rule of Thumb**

- Use **private IPs** when staying internal.
    
- Use **public IPs** when you need to expose something.
    
- Use **different IP blocks** in cloud and on-prem to avoid conflict.
    
- Subnet smart: group services, control traffic, and scale cleanly.

---
### 🧠 **What’s a Network Packet Broker (NPB)?**

Think of it like the **mailroom in a giant office building**. Everyone’s packets (data) are coming from different floors (devices: routers, firewalls, switches), and the packet broker:

- **Collects** them
    
- **Organizes and filters** them (only what's needed)
    
- **Forwards** them to the security team (monitoring tools, IDS/IPS, etc.)
    

---

### 🔍 **Why do we need it?**

Back in the day, we’d just mirror ports with SPAN and throw it into Wireshark.  
Now? Network speeds are insane. Packet floods are real. Sending every packet to one monitoring box is like trying to drink Niagara Falls with a straw.

So we need a **middle-person (NPB)** to:

- **Filter out junk**
    
- **De-dupe packets**
    
- **Pre-process sensitive data**
    
- Forward just the _right_ traffic to the tools that matter.
    

---

### ⚙️ **What it connects to:**

- Switches
    
- Firewalls
    
- Routers
    
- Cloud VMs (yes, they work in the cloud too)
    

And sends the cleaned-up traffic to:

- IDS/IPS
    
- Forensic systems
    
- Logging/alerting platforms (like Splunk, ELK, etc.)
    

---

### 🌩️ **In the Cloud?**

Yup. Most cloud providers now let you:

- Use a **virtual packet broker** (appliance in a VM)
    
- Or, install **agents** on VMs to forward packet copies.
---

### 🧠 In Plain English:

Think of CDNs as **supercharged delivery guys** stationed all around the world. When you hit up a site or stream a video, the CDN doesn’t ship it from the original server (which could be halfway across the planet). Instead, it **serves the content from the nearest local “warehouse”** (called an _edge location_).

---

### 🔁 Real-World Example:

If someone in Asia tries to access a U.S.-hosted website, instead of pulling the data all the way from the U.S., the CDN reroutes that request to a nearby node in Asia. It’s like having a **backup library on every continent**.

---

### 🧱 What It Does:

- **Reduces latency** (distance = delay)
    
- **Improves reliability** (if one edge goes down, another takes over)
    
- **Balances traffic** (avoids overwhelming one server)
    
- **Caches static content** (images, scripts, videos, etc.)
    

---

### 🛠️ Bonus Fact:

All the big cloud players — AWS (CloudFront), Azure (CDN), GCP (Cloud CDN) — offer this, and most streaming services rely on it _heavily_.

---
---

### 🛠️ What is a CloudFormation Template?

A **CloudFormation Template** is basically **blueprint code** (written in JSON or YAML) that tells AWS,

> “Hey, spin up this exact setup every single time I say so.”

This includes things like:

- EC2 instances (your servers)
    
- VPCs (your virtual network space)
    
- IAM roles (permissions)
    
- S3 buckets (storage)  
    ...and a bunch more.
    

---

### ⚙️ Why it Matters:

CloudFormation gives you **Infrastructure as Code (IaC)** —  
you automate your entire cloud setup, like:

- “Click this, and boom, your full architecture is deployed in 30 seconds.”
    
- “Need to clone it in another region? Just run the same template.”
    

---

### 🔁 Real Use Cases:

- **Version control your infrastructure** in Git like software.
    
- **Avoid misclicks** or human errors in the AWS console.
    
- **Parameterize** stuff (like region, bucket name, size, etc.) for reuse.
    
- **Easily tear down and rebuild** environments for testing.
    

---

### 🧠 TL;DR:

> CloudFormation = A repeatable, scripted, automated way to build and manage your AWS cloud gear.  
> YAML or JSON. Set it, forget it, version it, and scale it.

---
### 🔒 **AWS WAF Web ACL — Your Web App's Bouncer**

Think of AWS WAF (Web Application Firewall) like the security guard at the door of your cloud application.  
It stops the sketchy traffic **before** it ever gets inside.

#### 🧱 What It Does:

- **Blocks web attacks** like:
    
    - SQL Injection (SQLi)
        
    - Cross-Site Scripting (XSS)
        
    - Bots & scraping attempts
        
- **Web ACL (Access Control List)** = Your custom rulebook
    
    - You decide what’s allowed or denied
        
    - Define conditions based on IPs, geolocation, request patterns, etc.
        

#### ⚙️ Integrated With:

- **CloudFront** (CDN for websites)
    
- **API Gateway** (for REST APIs)
    
- **ALB** (load balancers)
    

#### 💡 Features:

- **Managed rule sets** — AWS gives you pre-built protection rules so you’re not reinventing the wheel.
    
- **Real-time monitoring** — See threats as they happen.
    
- **Low false positives** — It's smart about not blocking legit traffic.
    

---

### ⚠️ TL;DR:

> AWS WAF Web ACL is your **automated security gate**, stopping bad requests from reaching your app,  
> and works great with other AWS services like CloudFront or ALB.

---

### 🚀 **ExpressRoute (Azure)**

Think of it as **your own private fast lane** to Microsoft’s cloud.

#### 🔐 What It Is:

- A **dedicated, private connection** between your local data center and Microsoft (Azure, 365, etc.)
    
- Skips the **public internet** entirely
    

#### 💪 Why It Matters:

- **Way more secure** (no public exposure = harder to attack)
    
- **Lower latency** and **faster speeds** (up to **100 Gbps**!)
    
- **High reliability** — perfect for:
    
    - Hybrid cloud (mix of on-prem + cloud)
        
    - Enterprise apps that can’t afford downtime
        

#### 🧩 Where It Connects:

- **Azure**
    
- **Microsoft 365**
    
- **Dynamics 365**
    

#### 📜 Bonus:

- Helps you stay in line with **security** and **regulatory** policies  
    (think HIPAA, FedRAMP, or internal compliance)
    

---

### ⚠️ TL;DR:

> ExpressRoute = **private tunnel** into Microsoft cloud.  
> Faster. Safer. Built for serious workloads.  
> Like skipping traffic and teleporting straight into Azure.

---
### 🔒 **VPC Endpoint (AWS)**

Think of it as a **private shortcut** to AWS services — no internet involved.

#### 🚫 What It _Avoids_:

- No **Internet Gateway**
    
- No **NAT**
    
- No **VPN**
    
- No public traffic exposure
    

#### 🛡️ What It **Does**:

- Lets resources **inside your VPC** connect to AWS services (like S3 or DynamoDB) **securely and privately**
    
- Keeps the traffic **inside the AWS backbone**
    
- **Improves security** (no public exposure = less attack surface)
    
- **Reduces latency** and **data transfer costs**
    

#### 🧠 Extra Power:

- Works with **IAM (Identity & Access Management)**  
    → means **fine-grained access control** (down to who can access what)
    

---

### ⚡ TL;DR:

> VPC Endpoint = **AWS-native private route** to services.  
> No public roads, no sketchy traffic, just clean secure lanes within AWS.

You want this when you're building secure cloud apps and don’t want your data ever touching the internet. Like a secure underground tunnel from your warehouse (VPC) to Amazon’s storage or database center. 🛣️🔐

---
### ⚖️ **What’s an SLA?**

An SLA is a contract between **you and the cloud provider**. It tells you:

- **What you’re guaranteed to get** (e.g., 99.99% uptime)
    
- **What happens if they screw up** (penalties or compensation)
    
- **Who owns what**, including **data rights** and responsibilities
    

Think of it like this:

> “We'll keep the lights on 99.99% of the time. If we don't, we owe you—maybe credits, maybe cash. But we’re not responsible for the mess _you_ make inside the house.”

---

### 🔄 **Shared Responsibility Model**

You and the cloud provider **share the workload**, but who handles what depends on what **type of cloud service** you’re using:

#### 🧱 **IaaS** (Infrastructure as a Service)

- You get the **raw bricks**: servers, networks, storage
    
- You manage **everything** above the hardware (OS, apps, data)
    
- Example: **VMs, EC2**
    

#### 🧰 **PaaS** (Platform as a Service)

- Cloud handles OS, runtime, and servers
    
- You manage your **apps and data**
    
- Example: **Azure App Service, AWS Lambda**
    

#### 🪄 **SaaS** (Software as a Service)

- You just use the app
    
- Cloud provider manages almost **everything**
    
- Example: **Microsoft 365, Gmail**
    

---

### 🔑 **Key Takeaway**

> **More control = more responsibility**  
> **Less control = less work, more cost**

In cyber terms: if you spin up an EC2 instance, patching the OS, securing ports, and encrypting data? All you, champ. But if you’re using a managed DB? AWS secures the platform — you just protect your own tables and queries.

---
### 🧠 In Summary — What to Burn into Your Brain:

- Cloud Deployment = _new_
    
- Cloud Migration = _move + rebuild_
    
- Change Management = _plan it, test it, document it_
    
- Review Boards = _business + risk decision-makers_
    
- Automate everything = _with scripts, templates, workflows_
    
- Monitor everything = _don’t trust it to just work forever_
    
- Document it all = _or you’ll regret it_
    
- Know FCAPS = _it's your cloud health check framework_
    

---